  -------
|  Kfold  |
  -------
PHM (18ch_tr)
1/5: 
fold 1/3 accuracy: 0.9411764705882353
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 2/3 accuracy: 0.9941176470588236
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  9  0  0  1  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 3/3 accuracy: 0.9411764705882353
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_3 (InputLayer)        [(None, 64000, 18)]          0         []                            
 batch_normalization_2 (Bat  (None, 64000, 18)            72        ['input_3[0][0]']             
 chNormalization)                                                                                 
 tf.__operators__.getitem_6  (None, 64000, 6)             0         ['batch_normalization_2[0][0]'
  (SlicingOpLambda)                                                 ]                             
 tf.__operators__.getitem_7  (None, 64000, 3)             0         ['batch_normalization_2[0][0]'
  (SlicingOpLambda)                                                 ]                             
 tf.__operators__.getitem_8  (None, 64000, 9)             0         ['batch_normalization_2[0][0]'
  (SlicingOpLambda)                                                 ]                             
 conv1d_6 (Conv1D)           (None, 7097, 16)             12304     ['tf.__operators__.getitem_6[0
                                                                    ][0]']                        
 conv1d_7 (Conv1D)           (None, 7097, 16)             6160      ['tf.__operators__.getitem_7[0
                                                                    ][0]']                        
 conv1d_8 (Conv1D)           (None, 7097, 16)             18448     ['tf.__operators__.getitem_8[0
                                                                    ][0]']                        
 layer_normalization_6 (Lay  (None, 7097, 16)             32        ['conv1d_6[0][0]']            
 erNormalization)                                                                                 
 layer_normalization_7 (Lay  (None, 7097, 16)             32        ['conv1d_7[0][0]']            
 erNormalization)                                                                                 
 layer_normalization_8 (Lay  (None, 7097, 16)             32        ['conv1d_8[0][0]']            
 erNormalization)                                                                                 
 global_average_pooling1d_6  (None, 16)                   0         ['layer_normalization_6[0][0]'
  (GlobalAveragePooling1D)                                          ]                             
 global_average_pooling1d_7  (None, 16)                   0         ['layer_normalization_7[0][0]'
  (GlobalAveragePooling1D)                                          ]                             
 global_average_pooling1d_8  (None, 16)                   0         ['layer_normalization_8[0][0]'
  (GlobalAveragePooling1D)                                          ]                             
 dense_8 (Dense)             (None, 8)                    136       ['global_average_pooling1d_6[0
                                                                    ][0]']                        
 dense_9 (Dense)             (None, 4)                    68        ['global_average_pooling1d_7[0
                                                                    ][0]']                        
 dense_10 (Dense)            (None, 4)                    68        ['global_average_pooling1d_8[0
                                                                    ][0]']                        
 concatenate_2 (Concatenate  (None, 16)                   0         ['dense_8[0][0]',             
 )                                                                   'dense_9[0][0]',             
                                                                     'dense_10[0][0]']            
 dropout_2 (Dropout)         (None, 16)                   0         ['concatenate_2[0][0]']       
 dense_11 (Dense)            (None, 17)                   289       ['dropout_2[0][0]']           
 activation_2 (Activation)   (None, 17)                   0         ['dense_11[0][0]']            
==================================================================================================
Total params: 37641 (147.04 KB)
Trainable params: 37605 (146.89 KB)
Non-trainable params: 36 (144.00 Byte)
__________________________________________________________________________________________________
None
mean accuracy: 0.9588235294117647
2/5: 
fold 1/3 accuracy: 0.9411764705882353
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 2/3 accuracy: 1.0
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 3/3 accuracy: 0.9411764705882353
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
Model: "model_5"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_6 (InputLayer)        [(None, 64000, 18)]          0         []                            
 batch_normalization_5 (Bat  (None, 64000, 18)            72        ['input_6[0][0]']             
 chNormalization)                                                                                 
 tf.__operators__.getitem_1  (None, 64000, 6)             0         ['batch_normalization_5[0][0]'
 5 (SlicingOpLambda)                                                ]                             
 tf.__operators__.getitem_1  (None, 64000, 3)             0         ['batch_normalization_5[0][0]'
 6 (SlicingOpLambda)                                                ]                             
 tf.__operators__.getitem_1  (None, 64000, 9)             0         ['batch_normalization_5[0][0]'
 7 (SlicingOpLambda)                                                ]                             
 conv1d_15 (Conv1D)          (None, 7097, 16)             12304     ['tf.__operators__.getitem_15[
                                                                    0][0]']                       
 conv1d_16 (Conv1D)          (None, 7097, 16)             6160      ['tf.__operators__.getitem_16[
                                                                    0][0]']                       
 conv1d_17 (Conv1D)          (None, 7097, 16)             18448     ['tf.__operators__.getitem_17[
                                                                    0][0]']                       
 layer_normalization_15 (La  (None, 7097, 16)             32        ['conv1d_15[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_16 (La  (None, 7097, 16)             32        ['conv1d_16[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_17 (La  (None, 7097, 16)             32        ['conv1d_17[0][0]']           
 yerNormalization)                                                                                
 global_average_pooling1d_1  (None, 16)                   0         ['layer_normalization_15[0][0]
 5 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_1  (None, 16)                   0         ['layer_normalization_16[0][0]
 6 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_1  (None, 16)                   0         ['layer_normalization_17[0][0]
 7 (GlobalAveragePooling1D)                                         ']                            
 dense_20 (Dense)            (None, 8)                    136       ['global_average_pooling1d_15[
                                                                    0][0]']                       
 dense_21 (Dense)            (None, 4)                    68        ['global_average_pooling1d_16[
                                                                    0][0]']                       
 dense_22 (Dense)            (None, 4)                    68        ['global_average_pooling1d_17[
                                                                    0][0]']                       
 concatenate_5 (Concatenate  (None, 16)                   0         ['dense_20[0][0]',            
 )                                                                   'dense_21[0][0]',            
                                                                     'dense_22[0][0]']            
 dropout_5 (Dropout)         (None, 16)                   0         ['concatenate_5[0][0]']       
 dense_23 (Dense)            (None, 17)                   289       ['dropout_5[0][0]']           
 activation_5 (Activation)   (None, 17)                   0         ['dense_23[0][0]']            
==================================================================================================
Total params: 37641 (147.04 KB)
Trainable params: 37605 (146.89 KB)
Non-trainable params: 36 (144.00 Byte)
__________________________________________________________________________________________________
None
mean accuracy: 0.9607843137254902
3/5: 
fold 1/3 accuracy: 0.8764705882352941
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 7  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  6]]
fold 2/3 accuracy: 0.9411764705882353
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 3/3 accuracy: 1.0
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
Model: "model_8"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_9 (InputLayer)        [(None, 64000, 18)]          0         []                            
 batch_normalization_8 (Bat  (None, 64000, 18)            72        ['input_9[0][0]']             
 chNormalization)                                                                                 
 tf.__operators__.getitem_2  (None, 64000, 6)             0         ['batch_normalization_8[0][0]'
 4 (SlicingOpLambda)                                                ]                             
 tf.__operators__.getitem_2  (None, 64000, 3)             0         ['batch_normalization_8[0][0]'
 5 (SlicingOpLambda)                                                ]                             
 tf.__operators__.getitem_2  (None, 64000, 9)             0         ['batch_normalization_8[0][0]'
 6 (SlicingOpLambda)                                                ]                             
 conv1d_24 (Conv1D)          (None, 7097, 16)             12304     ['tf.__operators__.getitem_24[
                                                                    0][0]']                       
 conv1d_25 (Conv1D)          (None, 7097, 16)             6160      ['tf.__operators__.getitem_25[
                                                                    0][0]']                       
 conv1d_26 (Conv1D)          (None, 7097, 16)             18448     ['tf.__operators__.getitem_26[
                                                                    0][0]']                       
 layer_normalization_24 (La  (None, 7097, 16)             32        ['conv1d_24[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_25 (La  (None, 7097, 16)             32        ['conv1d_25[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_26 (La  (None, 7097, 16)             32        ['conv1d_26[0][0]']           
 yerNormalization)                                                                                
 global_average_pooling1d_2  (None, 16)                   0         ['layer_normalization_24[0][0]
 4 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_2  (None, 16)                   0         ['layer_normalization_25[0][0]
 5 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_2  (None, 16)                   0         ['layer_normalization_26[0][0]
 6 (GlobalAveragePooling1D)                                         ']                            
 dense_32 (Dense)            (None, 8)                    136       ['global_average_pooling1d_24[
                                                                    0][0]']                       
 dense_33 (Dense)            (None, 4)                    68        ['global_average_pooling1d_25[
                                                                    0][0]']                       
 dense_34 (Dense)            (None, 4)                    68        ['global_average_pooling1d_26[
                                                                    0][0]']                       
 concatenate_8 (Concatenate  (None, 16)                   0         ['dense_32[0][0]',            
 )                                                                   'dense_33[0][0]',            
                                                                     'dense_34[0][0]']            
 dropout_8 (Dropout)         (None, 16)                   0         ['concatenate_8[0][0]']       
 dense_35 (Dense)            (None, 17)                   289       ['dropout_8[0][0]']           
 activation_8 (Activation)   (None, 17)                   0         ['dense_35[0][0]']            
==================================================================================================
Total params: 37641 (147.04 KB)
Trainable params: 37605 (146.89 KB)
Non-trainable params: 36 (144.00 Byte)
__________________________________________________________________________________________________
None
mean accuracy: 0.9392156862745097
4/5: 
fold 1/3 accuracy: 0.7647058823529411
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]]
fold 2/3 accuracy: 0.8235294117647058
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 3/3 accuracy: 0.9411764705882353
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
Model: "model_11"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_12 (InputLayer)       [(None, 64000, 18)]          0         []                            
 batch_normalization_11 (Ba  (None, 64000, 18)            72        ['input_12[0][0]']            
 tchNormalization)                                                                                
 tf.__operators__.getitem_3  (None, 64000, 6)             0         ['batch_normalization_11[0][0]
 3 (SlicingOpLambda)                                                ']                            
 tf.__operators__.getitem_3  (None, 64000, 3)             0         ['batch_normalization_11[0][0]
 4 (SlicingOpLambda)                                                ']                            
 tf.__operators__.getitem_3  (None, 64000, 9)             0         ['batch_normalization_11[0][0]
 5 (SlicingOpLambda)                                                ']                            
 conv1d_33 (Conv1D)          (None, 7097, 16)             12304     ['tf.__operators__.getitem_33[
                                                                    0][0]']                       
 conv1d_34 (Conv1D)          (None, 7097, 16)             6160      ['tf.__operators__.getitem_34[
                                                                    0][0]']                       
 conv1d_35 (Conv1D)          (None, 7097, 16)             18448     ['tf.__operators__.getitem_35[
                                                                    0][0]']                       
 layer_normalization_33 (La  (None, 7097, 16)             32        ['conv1d_33[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_34 (La  (None, 7097, 16)             32        ['conv1d_34[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_35 (La  (None, 7097, 16)             32        ['conv1d_35[0][0]']           
 yerNormalization)                                                                                
 global_average_pooling1d_3  (None, 16)                   0         ['layer_normalization_33[0][0]
 3 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_3  (None, 16)                   0         ['layer_normalization_34[0][0]
 4 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_3  (None, 16)                   0         ['layer_normalization_35[0][0]
 5 (GlobalAveragePooling1D)                                         ']                            
 dense_44 (Dense)            (None, 8)                    136       ['global_average_pooling1d_33[
                                                                    0][0]']                       
 dense_45 (Dense)            (None, 4)                    68        ['global_average_pooling1d_34[
                                                                    0][0]']                       
 dense_46 (Dense)            (None, 4)                    68        ['global_average_pooling1d_35[
                                                                    0][0]']                       
 concatenate_11 (Concatenat  (None, 16)                   0         ['dense_44[0][0]',            
 e)                                                                  'dense_45[0][0]',            
                                                                     'dense_46[0][0]']            
 dropout_11 (Dropout)        (None, 16)                   0         ['concatenate_11[0][0]']      
 dense_47 (Dense)            (None, 17)                   289       ['dropout_11[0][0]']          
 activation_11 (Activation)  (None, 17)                   0         ['dense_47[0][0]']            
==================================================================================================
Total params: 37641 (147.04 KB)
Trainable params: 37605 (146.89 KB)
Non-trainable params: 36 (144.00 Byte)
__________________________________________________________________________________________________
None
mean accuracy: 0.8431372549019608
5/5: 
fold 1/3 accuracy: 0.8823529411764706
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 2/3 accuracy: 1.0
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
fold 3/3 accuracy: 1.0
 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[[10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0]
 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10]]
Model: "model_14"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_15 (InputLayer)       [(None, 64000, 18)]          0         []                            
 batch_normalization_14 (Ba  (None, 64000, 18)            72        ['input_15[0][0]']            
 tchNormalization)                                                                                
 tf.__operators__.getitem_4  (None, 64000, 6)             0         ['batch_normalization_14[0][0]
 2 (SlicingOpLambda)                                                ']                            
 tf.__operators__.getitem_4  (None, 64000, 3)             0         ['batch_normalization_14[0][0]
 3 (SlicingOpLambda)                                                ']                            
 tf.__operators__.getitem_4  (None, 64000, 9)             0         ['batch_normalization_14[0][0]
 4 (SlicingOpLambda)                                                ']                            
 conv1d_42 (Conv1D)          (None, 7097, 16)             12304     ['tf.__operators__.getitem_42[
                                                                    0][0]']                       
 conv1d_43 (Conv1D)          (None, 7097, 16)             6160      ['tf.__operators__.getitem_43[
                                                                    0][0]']                       
 conv1d_44 (Conv1D)          (None, 7097, 16)             18448     ['tf.__operators__.getitem_44[
                                                                    0][0]']                       
 layer_normalization_42 (La  (None, 7097, 16)             32        ['conv1d_42[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_43 (La  (None, 7097, 16)             32        ['conv1d_43[0][0]']           
 yerNormalization)                                                                                
 layer_normalization_44 (La  (None, 7097, 16)             32        ['conv1d_44[0][0]']           
 yerNormalization)                                                                                
 global_average_pooling1d_4  (None, 16)                   0         ['layer_normalization_42[0][0]
 2 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_4  (None, 16)                   0         ['layer_normalization_43[0][0]
 3 (GlobalAveragePooling1D)                                         ']                            
 global_average_pooling1d_4  (None, 16)                   0         ['layer_normalization_44[0][0]
 4 (GlobalAveragePooling1D)                                         ']                            
 dense_56 (Dense)            (None, 8)                    136       ['global_average_pooling1d_42[
                                                                    0][0]']                       
 dense_57 (Dense)            (None, 4)                    68        ['global_average_pooling1d_43[
                                                                    0][0]']                       
 dense_58 (Dense)            (None, 4)                    68        ['global_average_pooling1d_44[
                                                                    0][0]']                       
 concatenate_14 (Concatenat  (None, 16)                   0         ['dense_56[0][0]',            
 e)                                                                  'dense_57[0][0]',            
                                                                     'dense_58[0][0]']            
 dropout_14 (Dropout)        (None, 16)                   0         ['concatenate_14[0][0]']      
 dense_59 (Dense)            (None, 17)                   289       ['dropout_14[0][0]']          
 activation_14 (Activation)  (None, 17)                   0         ['dense_59[0][0]']            
==================================================================================================
Total params: 37641 (147.04 KB)
Trainable params: 37605 (146.89 KB)
Non-trainable params: 36 (144.00 Byte)
__________________________________________________________________________________________________
None
mean accuracy: 0.9607843137254902
total mean accuracy: 0.9325490196078432
Total processing time: 816.02
